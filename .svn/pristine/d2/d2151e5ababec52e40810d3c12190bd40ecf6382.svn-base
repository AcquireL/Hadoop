package com.briup.hdfs.common;

import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.conf.Configured;
import org.apache.hadoop.fs.FSDataInputStream;
import org.apache.hadoop.fs.FileSystem;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.util.Tool;
import org.apache.hadoop.util.ToolRunner;
/*
 *  	使用自定以文件路径的方法展示文件内容
 */
public class ShowFileTest extends Configured implements Tool {
	public static void main(String[] args) throws Exception {
		ToolRunner.run(new ShowFileTest(), args);
	}
    //需要用到命名参数的代码
	public int run(String[] args) throws Exception {
		//1.获取配置对象
		Configuration conf=getConf();
		//conf.set("fs.defaultFS","hdfs://192.168.29.132:9000");
		System.out.println(conf);
		try { 
			//2.获取文件对象
			FileSystem fs=FileSystem.get(conf);
			//3.获取适当的输入流
			FSDataInputStream fsd=fs.open(new Path(conf.get("path")));
			//IOUtils.copyBytes(fsd,System.out,1024);
			String line=null;
			while((line=fsd.readLine())!=null) {
				System.out.println(line);
			}
			//4.关闭文件流
			fsd.close();
		} catch (Exception e) {
			e.printStackTrace();
		}
		return 0;
	}
}

